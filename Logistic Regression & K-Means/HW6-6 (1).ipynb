{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VGDKqNGv1Rtx"
   },
   "source": [
    "# Logistic Regression\n",
    "\n",
    "You will implement logistic regression classifier.\n",
    "\n",
    "Iris dataset with only 2 classes is provided to test the code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 166,
     "status": "ok",
     "timestamp": 1683776111993,
     "user": {
      "displayName": "Yen-Kuang Chen",
      "userId": "09824706370308406166"
     },
     "user_tz": 420
    },
    "id": "alBxk8lq1Rt4",
    "outputId": "9a5784a6-a52a-4107-8b89-fb6e7bfb2ea4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_width  sepal_length  petal_width  petal_length  class\n",
      "0          5.6           3.0          4.1           1.3      0\n",
      "1          5.4           3.9          1.7           0.4      1\n",
      "2          5.6           3.0          4.5           1.5      0\n",
      "3          5.0           3.5          1.6           0.6      1\n",
      "4          5.5           2.4          3.7           1.0      0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy.matlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# read dataset\n",
    "df = pd.read_csv(\"shuffled_2class_iris_dataset.csv\")\n",
    "print(df.head())\n",
    "\n",
    "df = df.values\n",
    "X = df[:,0:4]   # 100x4\n",
    "y = df[:,4]     # 100x1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "uCmn7QBC1Rue",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Zero out the mean\n",
    "diff = X.max(0) - X.min(0)\n",
    "X = X - diff\n",
    "\n",
    "# Create 90/10 trainig/test sets\n",
    "train_data = X[0:90,0:4]; train_label = y[0:90]\n",
    "test_data = X[90:100,0:4]; test_label = y[90:100]\n",
    "\n",
    "zz = np.ones((len(test_data),1))\n",
    "test_data = np.concatenate((zz,test_data), axis=1)  # 90x5\n",
    "# test_data = 10x5, the first column is all 1's\n",
    "#   1st feature of the first observation (1st row, 1st column): test_data[0,1]\n",
    "#   4th feature of the second observation (2nd row, 3th column): test_data[1,4]\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XyMKJ1us1Ruv"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "executionInfo": {
     "elapsed": 6271,
     "status": "ok",
     "timestamp": 1683776121576,
     "user": {
      "displayName": "Yen-Kuang Chen",
      "userId": "09824706370308406166"
     },
     "user_tz": 420
    },
    "id": "uw7RwLKT1Ruy",
    "outputId": "43d61e25-fc90-4f35-dbc2-dbaeb5bd295b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use batch gradient descent to find the optimal weights of the sigmoid function\n",
    "\n",
    "# Define the sigmoid function using numpy.exp\n",
    "def sigmod(t):\n",
    "    # To-do\n",
    "    # Compute the p given t\n",
    "    p = 1/(1 + np.exp(-t))\n",
    "    return (p)\n",
    "\n",
    "# Define the logistic regression inference function\n",
    "# It takes in a weight vector and a feature vector\n",
    "def lr_inferencing(w_vec, x_vec):\n",
    "    # To-do\n",
    "    # Compute the dot product of the weight and feature vectors\n",
    "    y = np.dot(w_vec, x_vec)\n",
    "    # Pass the dot product through the sigmoid function\n",
    "    predicted_y = sigmod(y)\n",
    "    # Return the predicted label (a value between 0 and 1)\n",
    "    return predicted_y\n",
    "\n",
    "# Train the model using the training data\n",
    "\n",
    "# Initialization\n",
    "alpha = 0.01\n",
    "MAX_EPOCHS = 1500\n",
    "cost_history = []\n",
    "\n",
    "# Initialization of X_train and y_train\n",
    "zz = np.ones((len(train_data),1))\n",
    "X_train = np.concatenate((zz,train_data), axis=1)  # 90x5\n",
    "#   X_train is 90x5; the first column is all 1's\n",
    "#     1st feature of the first observation (1st row, 2nd column): X_train[0,1]\n",
    "#     4th feature of the second observation (2nd row, 4th column): X_train[1,4]\n",
    "y_train = train_label.reshape(len(train_label),1)  # 90x1\n",
    "#   y_train is 90x1\n",
    "#     the label of the first observation (1st row): y_train[0]\n",
    "#     the label of the seventh observation (7th row): y_train[6]\n",
    "\n",
    "# Initialization of weight_vector\n",
    "w_vec = np.random.rand(5)\n",
    "\n",
    "# Loop for 1500 epochs\n",
    "for itr in range (MAX_EPOCHS):\n",
    "\n",
    "    # Initialize gradient and cost to 0\n",
    "    gradient = np.zeros(5)\n",
    "    cost = 0\n",
    "\n",
    "    # Loop over the training data\n",
    "    for i in range(len(X_train)):\n",
    "        # Extract the features and label for the current training example\n",
    "        x_vec=X_train[i][0:5]\n",
    "        y=y_train[i]\n",
    "        \n",
    "        # To-Do\n",
    "        # Use the current weights to predict the label for this example\n",
    "        y_pred = lr_inferencing(w_vec, x_vec)\n",
    "        # Compute the gradient for this example and add it to the running total\n",
    "        gradient += (y_pred - y) * x_vec\n",
    "        # Compute the cost for this example and add it to the running total\n",
    "        cost += -y*np.log(y_pred) - (1-y)*np.log(1-y_pred)\n",
    "\n",
    "    # To-Do\n",
    "    # Update the weights using the learning rate and the gradient\n",
    "    w_vec = w_vec - alpha*gradient\n",
    "    # Collect the cost function result from each epoch to generate a plot\n",
    "    # Append the current cost to the history of costs\n",
    "    cost_history.append(cost) # 1500x1\n",
    "      \n",
    "# Plot cost function vs iterations\n",
    "plt.plot(cost_history)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wrLm9qlX1RvE"
   },
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 171,
     "status": "ok",
     "timestamp": 1683776123885,
     "user": {
      "displayName": "Yen-Kuang Chen",
      "userId": "09824706370308406166"
     },
     "user_tz": 420
    },
    "id": "cJ3Z1ZHY1RvH",
    "outputId": "d172043e-7106-49d0-a636-b22f84adeb59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy = 1.000000\n"
     ]
    }
   ],
   "source": [
    "# Now use the test set to test the model\n",
    "\n",
    "# Print the actual and predicted class labels\n",
    "# Print the average accuracy\n",
    "\n",
    "correct_class_cnt = 0\n",
    "for i in range (len(test_data)):\n",
    "    \n",
    "    # To-do: \n",
    "    # Compute the probability for each test data and optimal weights\n",
    "    pn = lr_inferencing(w_vec, test_data[i][0:5])\n",
    "    # Find the predicted label y_hat based on threshold = 0.5\n",
    "    y_hat = 1 if pn >=0.5 else 0\n",
    "    # Check accuracy\n",
    "    # print('y={}, y_hat={}'.format(test_label[i], y_hat))\n",
    "    if (y_hat == test_label[i]):\n",
    "        correct_class_cnt += 1\n",
    "\n",
    "print('Average accuracy = {0:2f}'.format(correct_class_cnt/10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "IGDft1gb1RvW"
   },
   "source": [
    "Caution: accuracy may change drastically because of overfitting (data set too small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 149,
     "status": "ok",
     "timestamp": 1683776126569,
     "user": {
      "displayName": "Yen-Kuang Chen",
      "userId": "09824706370308406166"
     },
     "user_tz": 420
    },
    "id": "JUhU1bEY1Rva",
    "outputId": "8f0e0e6d-cb0d-44cc-f783-e5309eff7d91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.03108688 -3.56294114  2.58115678 -4.58617494 -1.5198854 ]\n"
     ]
    }
   ],
   "source": [
    "# Print the optimal weights\n",
    "print(w_vec)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
