<h1>Artificial Neural Networks:</h1>
<p align = "justify">a. Artificial neural networks are inspired by the structure and function of the human brain.<br/>
b. Activation functions introduce non-linearity to the network and help in modeling complex relationships. <br/>
c. MLP is a universal classifier. Any input-to-output mapping can be modeled by a network of sufficient size and appropriate weights. <br/>
d. Backpropagation is a common algorithm used to adjust the weights and biases in a neural network during training. <br/>
e. Backpropagation calculates the gradient of the loss function with respect to the networkâ€™s parameters. <br/>
f. The chain rule is a fundamental concept used in backpropagation to compute gradients layer by layer. <br/></p>

<h1>Convolutional Neural Networks:</h1>
<p align = "justify">a. CNNs typically consist of convolutional layers, pooling layers, and fully connected layers. <br/>
b. Convolution layers are responsible for extracting local features from the input data. <br/>
c. A convolutional layer simultaneously applies multiple filters to its inputs, making it capable of detecting multiple features in its inputs. <br/>
d. Pooling is typically applied after convolutional layers to progressively reduce the spatial size. <br/>
e. Skip connections are a common architectural element in CNNs, enabling better gradient flow and aiding in training deep networks. <br/></p>
