{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kbOZR6FWWQO2"
   },
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1712205777776,
     "user": {
      "displayName": "Yen-Kuang Chen",
      "userId": "09824706370308406166"
     },
     "user_tz": 420
    },
    "id": "Rh-Y5tYLWQO4"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zN-hhAJIWQO5"
   },
   "source": [
    "#### Functions for graph plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1712205779158,
     "user": {
      "displayName": "Yen-Kuang Chen",
      "userId": "09824706370308406166"
     },
     "user_tz": 420
    },
    "id": "lyPU7BezWQO6"
   },
   "outputs": [],
   "source": [
    "def plotting_classification_result10(Sp, Sn, w_vector, title):\n",
    "    \"\"\"\n",
    "    Plot classification result with the current weight vector\n",
    "    \"\"\"\n",
    "    # Initilize the scale for the plot\n",
    "    scale=10 # Scale for the plot\n",
    "\n",
    "    # Collect the coordinates for the postive and negative samples (for the easy of ploting)\n",
    "    Sp_x = [] # List to store x-coordinates of positive samples\n",
    "    Sp_y = [] # List to store y-coordinates of positive samples\n",
    "    Sn_x = [] # List to store x-coordinates of negative samples\n",
    "    Sn_y = [] # List to store y-coordinates of negative samples\n",
    "\n",
    "    # Iterate through positive samples and append x, y coordinates to respective lists\n",
    "    for i in Sp:\n",
    "        Sp_x.append(i[0])\n",
    "        Sp_y.append(i[1])\n",
    "\n",
    "    # Iterate through negative samples and append x, y coordinates to respective lists\n",
    "    for i in Sn:\n",
    "        Sn_x.append(i[0])\n",
    "        Sn_y.append(i[1])\n",
    "\n",
    "    w0=w_vector[0]\n",
    "    w1=w_vector[1]\n",
    "    w2=w_vector[2]\n",
    "    if w1 != 0:\n",
    "      x1 = -(w0-w2*scale/2)/w1\n",
    "      x2 = -(w0+w2*scale/2)/w1\n",
    "      X = np.array([x1, x2])\n",
    "      Y = np.array([-scale/2, scale/2])\n",
    "    elif w2 != 0:\n",
    "      y1 = -(w0-w1*scale/2)/w2\n",
    "      y2 = -(w0+w1*scale/2)/w2\n",
    "      X = np.array([-scale/2, scale/2])\n",
    "      Y = np.array([y1, y2])\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(5,5))\n",
    "    blue = plt.scatter(Sn_x, Sn_y, c ='b', label='Sn : {} elements'.format(len(Sn_x)))\n",
    "    red = plt.scatter(Sp_x, Sp_y, c='r', marker = \"^\", label='Sp : {} elements'.format(len(Sp_x)))\n",
    "    line = ax.plot(X, Y, c = 'green', label='Perceptron Decision Boundary')\n",
    "    plt.title(title)\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.ylim([-scale/2,scale/2])\n",
    "    plt.xlim([-scale/2,scale/2])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plotting_misclassification_over_updates(w_history, missed):\n",
    "    \"\"\"\n",
    "    Plot number of misclassifications vs. the updates graph\n",
    "    \"\"\"\n",
    "    n_epochs = range(len(w_history)+1) # Create a range of epochs for x-axis of plot\n",
    "    fig, ax = plt.subplots(figsize=(5, 5)) # Create a plot figure\n",
    "    ax.plot(n_epochs, missed+[0], c = 'green') # Plot number of misclassifications vs. epochs\n",
    "    plt.ylabel('Number of Misclassifications') # Set y-axis label\n",
    "    plt.xlabel('Number of Epochs') # Set x-axis label\n",
    "    plt.ylim(bottom=0) # Set lower limit of y-axis to 0\n",
    "    plt.xlim(left=0) # Set lower limit of x-axis to 0\n",
    "    plt.show() # Display the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ndt1N9d_WQO7"
   },
   "source": [
    "#### Training perceptron learning algorithm (PLA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "executionInfo": {
     "elapsed": 254,
     "status": "ok",
     "timestamp": 1712205782133,
     "user": {
      "displayName": "Yen-Kuang Chen",
      "userId": "09824706370308406166"
     },
     "user_tz": 420
    },
    "id": "KDT5x4lrWQO8"
   },
   "outputs": [],
   "source": [
    "def activation_fn(x):\n",
    "    \"\"\"\n",
    "    Activation function to determine the output based on input value\n",
    "    \"\"\"\n",
    "    if x >= 0:\n",
    "        y = 1 # Positive Sample Set\n",
    "    else:\n",
    "        y = -1 # Negative Sample Set\n",
    "    return y\n",
    "\n",
    "\n",
    "def misclassified(dataset, w_vector):\n",
    "    \"\"\"\n",
    "    Function to calculate the number of misclassifications in the dataset using current weight vector\n",
    "    \"\"\"\n",
    "    misclassifications = 0\n",
    "    for sample in dataset: # The first two in samples are the x,y coordinates. The last one in sample is the label.\n",
    "        y = (w_vector[0]+(sample[0]*w_vector[1])+(sample[1]*w_vector[2]))\n",
    "        y = activation_fn(y)\n",
    "        if y != sample[2]:\n",
    "            misclassifications += 1\n",
    "    return misclassifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "executionInfo": {
     "elapsed": 415,
     "status": "ok",
     "timestamp": 1712205784775,
     "user": {
      "displayName": "Yen-Kuang Chen",
      "userId": "09824706370308406166"
     },
     "user_tz": 420
    },
    "id": "ipL24KlXSk6c"
   },
   "outputs": [],
   "source": [
    "def perceptron_training(w_vec, training_samples):\n",
    "    \"\"\"\n",
    "    Function to train the perceptron\n",
    "    \"\"\"\n",
    "    w_vectors = [w_vec] # List to store weight vectors at each epoch\n",
    "    missed = [misclassified(training_samples, w_vec)] # List to store number of misclassifications at each epoch\n",
    "\n",
    "    # To-Do\n",
    "    # Need a while loop to continue training until no misclassifications\n",
    "        # Using a for loop to iterate through each sample in the dataset\n",
    "            # Compute perceptron output\n",
    "            # If misclassified,\n",
    "                # update weights\n",
    "                # Calculate misclassification count after weight updates\n",
    "    while missed[-1] > 0:\n",
    "        for sample in training_samples:\n",
    "            x1, x2, op_label = sample\n",
    "            sign = w_vec[0] + (x1 * w_vec[1]) + (x2 * w_vec[2])\n",
    "            cls_sign = activation_fn(sign)\n",
    "            if cls_sign != op_label:\n",
    "                misclassifications = True\n",
    "                w_vec[0] += op_label\n",
    "                w_vec[1] += op_label * x1\n",
    "                w_vec[2] += op_label * x2\n",
    "                w_vectors.append(w_vec.copy())\n",
    "                num_miss = misclassified(training_samples, w_vec)\n",
    "                missed.append(num_miss)\n",
    "\n",
    "    return w_vectors, missed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "executionInfo": {
     "elapsed": 272,
     "status": "ok",
     "timestamp": 1712205787862,
     "user": {
      "displayName": "Yen-Kuang Chen",
      "userId": "09824706370308406166"
     },
     "user_tz": 420
    },
    "id": "Ha-g9zKwERTO"
   },
   "outputs": [],
   "source": [
    "def generate_samples(subset):\n",
    "    \"\"\"\n",
    "    Generate positive and negative samples\n",
    "    \"\"\"\n",
    "    # Initilize the dataset\n",
    "    Sn = [] # List to store negative samples\n",
    "    Sp = [] # List to store positive samples\n",
    "    num_n = 0 # Counter for negative samples\n",
    "    num_p = 0 # Counter for positive samples\n",
    "\n",
    "    while len(Sp) < 20 or len(Sn) < 20:\n",
    "      i1, i2 = np.random.uniform(-5, 5, 2)\n",
    "      if i1 + i2 >= 0 and len(Sp) < 20:\n",
    "          Sp.append([i1, i2, 1])\n",
    "      elif i1 + i2 < 0 and len(Sn) < 20:\n",
    "          Sn.append([i1, i2, -1])\n",
    "\n",
    "    # Splitting samples into training and testing samples\n",
    "    testing_samples = Sp[10:] + Sn[10:]\n",
    "\n",
    "    # First split: subset of the samples used for training\n",
    "    training_samples = Sp[:subset] + Sn[:subset]\n",
    "\n",
    "    return training_samples, testing_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 100% training samples\n",
      "Accuracy : 0.9420000000000001\n",
      "Standard deviation: 0.06772001181334804\n",
      "===============================\n",
      "Using 50% training samples\n",
      "Accuracy : 0.912\n",
      "Standard deviation: 0.08692525524840292\n"
     ]
    }
   ],
   "source": [
    "acc_100_list = []\n",
    "acc_50_list = []\n",
    "\n",
    "for _ in range(100):\n",
    "    # ================================\n",
    "    # Using 100% of the training samples\n",
    "    training_data, testing_data = generate_samples(10)\n",
    "\n",
    "    # Train the PLA boundary using the training samples\n",
    "    w_vector = [np.random.uniform(-1/4, 1/4), np.random.uniform(-1, 1), np.random.uniform(-1, 1)]\n",
    "    w_history, missed = perceptron_training(w_vector, training_data)\n",
    "\n",
    "    # Test the accuracy on the unseen testing samples\n",
    "    num_misclassified = misclassified(testing_data, w_history[-1])\n",
    "    accuracy_100 = (len(testing_data) - num_misclassified) / len(testing_data)\n",
    "\n",
    "    acc_100_list.append(accuracy_100)\n",
    "\n",
    "    # ================================\n",
    "    # Using 50% of the training samples\n",
    "    training_data, testing_data = generate_samples(5)\n",
    "\n",
    "    # Train the PLA boundary using the training samples\n",
    "    w_vector = [np.random.uniform(-1/4, 1/4), np.random.uniform(-1, 1), np.random.uniform(-1, 1)]\n",
    "    w_history, missed = perceptron_training(w_vector, training_data)\n",
    "\n",
    "    # Test the accuracy on the unseen testing samples\n",
    "    num_misclassified = misclassified(testing_data, w_history[-1])\n",
    "    accuracy_50 = (len(testing_data) - num_misclassified) / len(testing_data)\n",
    "\n",
    "    acc_50_list.append(accuracy_50)\n",
    "\n",
    "print('Using 100% training samples')\n",
    "print('Accuracy : %s' % np.mean(acc_100_list))\n",
    "print('Standard deviation: %s' % np.std(acc_100_list))\n",
    "print('===============================')\n",
    "print('Using 50% training samples')\n",
    "print('Accuracy : %s' % np.mean(acc_50_list))\n",
    "print('Standard deviation: %s' % np.std(acc_50_list))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
