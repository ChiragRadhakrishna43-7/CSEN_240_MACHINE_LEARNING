{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"gpuClass":"standard"},"cells":[{"cell_type":"markdown","metadata":{"id":"ml58PJ9UDwRk"},"source":["**Principal Component Analysis**\n","\n","You will implement dimensionality reduction with PCA.  \n","\n","1). Read iris_dataset.csv (4 features, hence 4 PCs) and remove the first class\n","\n","2). Find the principal components\n","\n","3). Recontruct the dataset (X_hat)\n","\n","4). Determine the accuracy of X_hat for 1-4 PCs using a LBF SVM classifier (provided)\n"]},{"cell_type":"code","metadata":{"id":"b3DA-QxT0O6X"},"source":["import numpy as np\n","import pandas as pd\n","from numpy import linalg as LA\n","import matplotlib.pyplot as plt\n","from sklearn.svm import SVC # This package will help you run the SVM model directly\n","from sklearn.metrics import accuracy_score # Use accruacy_score to find out accuracy of your model\n","from sklearn.model_selection import train_test_split\n","\n","# Load data - 150 observations, 4 features, 3 classes \n","df = pd.read_csv(\"iris_dataset.csv\", header=None)\n","data = df.values\n","\n","# Remove the first class and change the class index\n","X_raw = data[50:,0:4]               # From 150 to 100 samples\n","y = np.subtract(data[50:,4],2)  # From class 2/3 to class 0/1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["SVM classifier (with 20% of the data as the test sets)"],"metadata":{"id":"EXUbvn1ze49w"}},{"cell_type":"code","source":["def svm_accuracy(X_hat, y, num_pc):\n","    X_train, X_test, y_train, y_test = train_test_split(X_hat, y, test_size=0.2)\n","\n","    clf = SVC(kernel='linear') # Use the linear function of the SVM algorithm\n","    clf.fit(X_train,y_train) # Train the model using the x_train and y_train\n","    y_pred = clf.predict(X_test) # Run prediction after training on the testing dataset\n","    print(num_pc, accuracy_score(y_test,y_pred)) # Print your final accuracy"],"metadata":{"id":"G6VJ3UXn-X3v"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["PCA (Your code goes here)"],"metadata":{"id":"ceZTciFpe-ZO"}},{"cell_type":"code","source":["def PCA(X, Num_PC):\n","  # Note that the matrix X in the program is transpose of that in the slides\n","  # Note that eigenvectors in the program is transpose of those in the slides\n","\n","  # To-Do\n","  # First, compute the the covariance matrix\n","  # Second, use LA.eig to compute the eigen_values, eigen_vectors\n","  # Third, sort the eigenvalues/the eigvenvectors in descending order\n","  # Fourth, select the first Num_PC eigenvectors\n","  # Fifth, transform the data into the desired dimension  \n","     \n","  return X_reduced"],"metadata":{"id":"Eg7QAhj2y9w4"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O-L8WvJIAKeY"},"source":["# Perform zero means\n","u = [np.mean(X_raw[:,0]), np.mean(X_raw[:,1]), np.mean(X_raw[:,2]), np.mean(X_raw[:,3])]\n","XM = np.subtract(X_raw,u)  # Subtracting the mean from each feature\n","\n","# Visualize the dataset with the projection to 2 principal components\n","X_pca = PCA(XM,2)  # Applying PCA with 2 components\n","\n","plt.figure(figsize=(8,6))\n","\n","# Scatter plot for class 0\n","plt.scatter(X_pca[0:50,0], X_pca[0:50,1], color='green', marker='o', label='0')\n","\n","# Scatter plot for class 1\n","plt.scatter(X_pca[50:100,0], X_pca[50:100,1], color='blue', marker='s', label='1')\n"," \n","plt.title(\"PCA components plot for IRIS Dataset\", fontsize=14)\n","plt.legend()\n","plt.show()\n","\n","# Measuring the accuracy vs. the number of components\n","for i in range(4):\n","  num_pc = i+1\n","  X_hat = PCA(XM,num_pc) # Applying PCA with the current number of components\n","  for r in range(10):\n","    # Call the function evaluate_accuracy \n","    svm_accuracy(X_hat, y, num_pc)  # classification accuracy with 1-4 PC"],"execution_count":null,"outputs":[]}]}