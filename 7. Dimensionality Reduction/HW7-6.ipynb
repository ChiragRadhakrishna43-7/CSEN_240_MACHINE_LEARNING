{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"gpuClass":"standard"},"cells":[{"cell_type":"markdown","metadata":{"id":"ml58PJ9UDwRk"},"source":["## Setup\n","**Linear Discriminant Analysis**\n","\n","You will implement dimensionality reduction with LDA.  \n","\n","1). Read iris_dataset.csv (4 features, hence 4 PCs) and remove the first class\n","\n","2). Find the LDA components\n","\n","3). Recontruct the dataset (X_hat)\n","\n","4). Determine the accuracy of X_hat for 1-4 PCs using a LBF SVM classifier (provided)\n"]},{"cell_type":"code","metadata":{"id":"b3DA-QxT0O6X"},"source":["import numpy as np\n","import pandas as pd\n","from numpy import linalg as LA\n","import matplotlib.pyplot as plt\n","from sklearn.svm import SVC # This package will help you run the SVM model directly\n","from sklearn.metrics import accuracy_score # Use accruacy_score to find out accuracy of your model\n","from sklearn.model_selection import train_test_split\n","\n","# Load data - 150 observations, 4 features, 3 classes\n","df = pd.read_csv(\"iris_dataset.csv\", header=None)\n","data = df.values\n","\n","# Remove the first class and change the class index\n","X_raw = data[50:,0:4]               # From 150 to 100 samples\n","y = (np.rint(np.subtract(data[50:,4],2))).astype(int) # From class 2/3 to class 0/1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["SVM classifier (with 20% of the data as the test sets)"],"metadata":{"id":"9lOKaQBPeZ_D"}},{"cell_type":"code","source":["def svm_accuracy(X_hat, y, num_pc):\n","    X_train, X_test, y_train, y_test = train_test_split(X_hat, y, test_size=0.2)\n","\n","    clf = SVC(kernel='linear') # Use the linear function of the SVM algorithm\n","    clf.fit(X_train,y_train) # Train the model using the x_train and y_train\n","    y_pred = clf.predict(X_test) # Run prediction after training on the testing dataset\n","    print(num_pc, accuracy_score(y_test,y_pred)) # Print your final accuracy"],"metadata":{"id":"osNzDZmuhZ7o"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["LDA (Your code goes here)"],"metadata":{"id":"9hIH0w1xe6mc"}},{"cell_type":"code","source":["# 2-class LDA\n","def LDA(X, y, Num_PC):\n","  # Note that the matrix X in the program is transpose of that in the slides\n","  # Note that eigenvectors in the program is transpose of those in the slides\n","\n","  # Setup\n","  dim = len(X[0])\n","  sum = np.zeros((2,dim))\n","  means = np.zeros((2,dim))\n","  count = np.zeros(2)\n","  Sw = np.zeros((dim,dim))\n","\n","  # To-Do\n","  # First, compute class means\n","  # Second, compute within-class scatter matrix (Sw)\n","  # Third, compute between-class scatter matrix (Sb)\n","  # Fourth, compute Fisher's criterion matrix using LA.pinv() to invert Sw\n","  # Fifth, compute the eigenvalues & eigenvectors of Fisher's criterion matrix\n","  # Sixth, sort the eigenvalues & eigenvectors in descending order\n","  # Seventh, transform the data by selecting the first Num_PC eigenvectors to achieve the desired dimension of our final reduced data.\n","\n","  return X_reduced"],"metadata":{"id":"vYl3DwfTmAsg"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O-L8WvJIAKeY"},"source":["# Perform zero means\n","u = [np.mean(X_raw[:,0]), np.mean(X_raw[:,1]), np.mean(X_raw[:,2]), np.mean(X_raw[:,3])]\n","XM = np.subtract(X_raw,u)  # Subtracting the mean from each feature\n","\n","# Visualize the dataset with the projection to 2 principal components\n","X_lda = LDA(XM, y, 2)  # Applying LDA with 2 components\n","\n","plt.figure(figsize=(8,6))\n","\n","# Scatter plot for class 0\n","plt.scatter(X_lda[0:50,0], X_lda[0:50,1], color='green', marker='o', label='0')\n","\n","# Scatter plot for class 1\n","plt.scatter(X_lda[50:100,0], X_lda[50:100,1], color='blue', marker='s', label='1')\n","\n","plt.title(\"LDA components plot for IRIS Dataset\", fontsize=14)\n","plt.legend()\n","plt.show()\n","\n","# Measuring the accuracy vs. the number of components\n","for i in range(4):\n","  num_pc = i+1\n","  X_hat = LDA(XM, y, num_pc) # Applying PCA with the current number of components\n","  for r in range(10):\n","    # Call the function evaluate_accuracy\n","    svm_accuracy(X_hat, y, num_pc)  # classification accuracy with 1-4 PC"],"execution_count":null,"outputs":[]}]}