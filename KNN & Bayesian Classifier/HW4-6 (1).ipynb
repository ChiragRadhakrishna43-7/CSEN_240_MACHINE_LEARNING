{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ssMWrKhNakJb"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8fINWmGc_wOx"
   },
   "source": [
    "# Bayesian Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ktiwY7zk_umX"
   },
   "outputs": [],
   "source": [
    "# Define a function to calculate the likelihood of a given data point x\n",
    "# given a normal distribution with specified mean and standard deviation\n",
    "def pdf(mean, sd, x):\n",
    "  # To-do\n",
    "  # vector divide of the following two\n",
    "  # vector substract, vector divide, vector square, vector multiply\n",
    "  # vector multiply, vector multiply, vector square root, vector multiply\n",
    "  e = -((x-mean)**2 / (2*(sd**2)))\n",
    "  likelihood = np.exp(e) / np.sqrt(2*np.pi*(sd**2))\n",
    "  return likelihood\n",
    "\n",
    "# Define a function to train a binary Bayes classifier\n",
    "# given a dataset and the number of features (dimensions)\n",
    "def bindary_bc_training(dataset, dim):\n",
    "  # Initialize variables to store sums and counts for positive and negative samples\n",
    "  sum_p = np.zeros(dim)\n",
    "  sum_n = np.zeros(dim)\n",
    "  sqr_sum_p = np.zeros(dim)\n",
    "  sqr_sum_n = np.zeros(dim)\n",
    "  count_p = 0\n",
    "  count_n = 0\n",
    "\n",
    "  # Iterate over each sample in the dataset\n",
    "  for each in range(len(dataset)):\n",
    "    # Extract the feature values (x_train) and class label (last element)\n",
    "    x_train=dataset[each][0:dim]\n",
    "    y_train=dataset[each][dim]\n",
    "    # If the class label is positive, update the corresponding sums and counts\n",
    "    if y_train > 0:\n",
    "      # To-Do\n",
    "      # vector sum\n",
    "      # vector square, vector sum\n",
    "      # scalar add\n",
    "      sum_p += x_train\n",
    "      sqr_sum_p += x_train ** 2\n",
    "      count_p += 1  \n",
    "    # If the class label is negative, update the corresponding sums and counts\n",
    "    else :\n",
    "      # To-Do\n",
    "      # vector sum\n",
    "      # vector square, vector sum\n",
    "      # scalar add\n",
    "      sum_n += x_train\n",
    "      sqr_sum_n += x_train ** 2\n",
    "      count_n += 1\n",
    "  # Calculate the mean, variance, and standard deviation for positive samples\n",
    "  # To-Do\n",
    "  # vector divide\n",
    "  # vector multiply, vector subtract, vector divide\n",
    "  # vector sqrt\n",
    "  mean_p = sum_p / count_p\n",
    "  variance_p = (sqr_sum_p / (count_p - 1)) - (mean_p ** 2)\n",
    "  sd_p = np.sqrt(variance_p)\n",
    "\n",
    "  # Calculate the mean, variance, and standard deviation for negative samples\n",
    "  # To-Do\n",
    "  # vector divide\n",
    "  # vector multiply, vector subtract, vector divide\n",
    "  # vector sqrt\n",
    "  mean_n = sum_n / count_n\n",
    "  variance_n = (sqr_sum_n / (count_n - 1)) - (mean_n ** 2)\n",
    "  sd_n = np.sqrt(variance_n)\n",
    "  # Return the mean and standard deviation for both classes\n",
    "  return mean_p, sd_p, mean_n, sd_n\n",
    "\n",
    "# Define a function to classify a new data point x\n",
    "# based on the Bayes classifier trained on positive and negative samples\n",
    "def bindary_bc_inferencing(mean_p, sd_p, mean_n, sd_n, x, dim, p_pos, p_neg):\n",
    "  # Calculate the likelihood of the new data point being in the positive and negative classes\n",
    "  p_p = pdf (mean_p, sd_p, x)\n",
    "  p_n = pdf (mean_n, sd_n, x)\n",
    "  #print (p_p)\n",
    "\n",
    "  # Compare the product of likelihoods for each class\n",
    "  # If the product for positive class is higher, return 1 (positive class)\n",
    "  # Otherwise, return -1 (negative class)\n",
    "  # print (np.prod( p_p))\n",
    "  if np.multiply( np.prod( p_p), p_pos) > np.multiply( np.prod( p_n), p_neg):\n",
    "    return 1\n",
    "  else :\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "beGsr3WooRSD"
   },
   "outputs": [],
   "source": [
    "def generate_samples(target_num_samples,dim):\n",
    "    # Initilize the dataset\n",
    "    Sn = [] # List to store negative samples\n",
    "    Sp = [] # List to store positive samples\n",
    "    num_n = 0 # Counter for negative samples\n",
    "    num_p = 0 # Counter for positive samples\n",
    "\n",
    "    # Generate samples until the target number is reached for both positive and negative samples\n",
    "    while num_p < target_num_samples*2 or num_n < target_num_samples*2:\n",
    "      # Generate a random vector within the range [-5, 5] with dimension (dim+1)\n",
    "      random_sample = np.random.uniform(-5, 5, (dim+1))\n",
    "      # Set the last dimension to 0 temporally\n",
    "      random_sample[dim] = 0\n",
    "      # Compute the sum of the vector components\n",
    "      sum = np.sum(random_sample)\n",
    "      # If the sum is positive, append the sample to Sp\n",
    "      if sum > 0:\n",
    "        if num_p < target_num_samples*2:\n",
    "          random_sample[dim] = 1\n",
    "          Sp.append(random_sample)\n",
    "          num_p +=1\n",
    "      elif num_n < target_num_samples*2:\n",
    "        random_sample[dim] = -1\n",
    "        Sn.append(random_sample)\n",
    "        num_n +=1\n",
    "\n",
    "\n",
    "    # Split the dataset in to training (Sp, Sn) and testing (Tp, Tn)\n",
    "    # The last target_num_samples samples from Sn and Sp are used for testing.\n",
    "    Tp = Sp[target_num_samples:]\n",
    "    Tn = Sn[target_num_samples:]\n",
    "\n",
    "    # The first target_num_samples samples from Sn and Sp are used for training.\n",
    "    Sp = Sp[:target_num_samples]\n",
    "    Sn = Sn[:target_num_samples]\n",
    "\n",
    "    # Combine positive and negative samples to create the dataset\n",
    "    training_samples = Sn + Sp\n",
    "    # Combine positive and negative samples to create the dataset\n",
    "    testing_samples = Tp + Tn\n",
    "\n",
    "    return training_samples, testing_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1673,
     "status": "ok",
     "timestamp": 1714026103653,
     "user": {
      "displayName": "Yen-Kuang Chen",
      "userId": "09824706370308406166"
     },
     "user_tz": 420
    },
    "id": "iFsBMaYMoJqj",
    "outputId": "9ff9b07c-d148-4fb0-e801-821989d06ecb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension = 2\n",
      "Precision (average & SD): 0.9437738525648799 0.04748678480738364\n",
      "Recall (average & SD): 0.9475000000000001 0.04636809247747852\n",
      "F1 (average & SD): 0.9451557859364971 0.04175477254618505\n",
      "Dimension = 10\n",
      "Precision (average & SD): 0.9461777780362494 0.02371612382984716\n",
      "Recall (average & SD): 0.9436666666666665 0.0212988001748664\n",
      "F1 (average & SD): 0.9446808372572308 0.016845020259279635\n"
     ]
    }
   ],
   "source": [
    "# Define the dimension of the data\n",
    "\n",
    "for dim in [2, 10]:\n",
    "\n",
    "  print (\"Dimension =\", dim)\n",
    "\n",
    "  # Define the number of samples to generate\n",
    "  target_num_samples=40*dim # This is the number of positive samples in the testing set\n",
    "\n",
    "  bc_precision_list = []\n",
    "  bc_recall_list = []\n",
    "  bc_f1_list = []\n",
    "\n",
    "  # Try 10 times\n",
    "  for r in range(30):\n",
    "\n",
    "    dataset, testing_dataset = generate_samples(target_num_samples,dim)\n",
    "\n",
    "    true_positive = 0  # Counter for true positive samples\n",
    "    true_negative = 0  # Counter for true negative samples\n",
    "    false_positive = 0 # Counter for false positive samples\n",
    "    false_negative = 0 # Counter for false negative samples\n",
    "\n",
    "    # Calculate the Gausian distribution based on training data\n",
    "    mean_p, sd_p, mean_n, sd_n = bindary_bc_training(dataset, dim)\n",
    "\n",
    "    # Loop through the testing_dataset\n",
    "    for each in range(len(testing_dataset)):\n",
    "      # Make a prediction using the bindary_bc_inferencing function with the testing sample\n",
    "      prediction = bindary_bc_inferencing(mean_p, sd_p, mean_n, sd_n, testing_dataset[each][0:dim], dim, 0.5, 0.5) # Prior probability = 0.5 for both classes\n",
    "\n",
    "      # Increment the appropriate counters based on whether the inferencing is true positive, true negative, false positive or false negative\n",
    "      if testing_dataset[each][dim] == 1:\n",
    "        if prediction == 1:\n",
    "          # To-Do\n",
    "          # increment the appropriate counter\n",
    "          true_positive += 1\n",
    "        else :\n",
    "          # To-Do\n",
    "          # increment the appropriate counter\n",
    "          false_negative += 1\n",
    "      else :\n",
    "        if prediction == -1:\n",
    "          # To-Do\n",
    "          # increment the appropriate counter\n",
    "          true_negative += 1\n",
    "        else :\n",
    "          # To-Do\n",
    "          # increment the appropriate counter\n",
    "          false_positive += 1\n",
    "    # Calculate precision\n",
    "    # To-Do\n",
    "    # calculate the precision using the the appropriate counters\n",
    "    precision = true_positive/(false_positive + true_positive)\n",
    "    bc_precision_list.append(precision)\n",
    "\n",
    "    # Calculate recall\n",
    "    # To-Do\n",
    "    # calculate the recall using the the appropriate counters\n",
    "    recall = true_positive/(false_negative + true_positive)\n",
    "    bc_recall_list.append(recall)\n",
    "\n",
    "    # Calculate F1 score\n",
    "    # To-Do\n",
    "    # calculate the score using precision and recall\n",
    "    precision_inv = 1/precision\n",
    "    recall_inv = 1/recall\n",
    "    f1 = 2/(precision_inv + recall_inv)\n",
    "    bc_f1_list.append(f1)\n",
    "\n",
    "  # print the result\n",
    "  print(\"Precision (average & SD):\", np.mean(bc_precision_list), np.std(bc_precision_list))\n",
    "  print(\"Recall (average & SD):\", np.mean(bc_recall_list), np.std(bc_recall_list))\n",
    "  print(\"F1 (average & SD):\", np.mean(bc_f1_list), np.std(bc_f1_list))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
