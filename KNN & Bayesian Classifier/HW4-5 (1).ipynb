{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ssMWrKhNakJb"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8fINWmGc_wOx"
   },
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ktiwY7zk_umX"
   },
   "outputs": [],
   "source": [
    "# Define a function to calculate the distance between two points\n",
    "def distance(point1, point2):\n",
    "  return (np.linalg.norm(point1 - point2))\n",
    "\n",
    "# Define a function to perform k-nearest neighbors (KNN) inference on a dataset\n",
    "# when k = 1\n",
    "def knn_inferencing(dataset, testing_point, dim):\n",
    "\n",
    "  # Define a large number\n",
    "  min_length=dim*dim*20\n",
    "  # Initialize the minimum label to 0\n",
    "  min_label=0\n",
    "  # Extract the feature values from the testing point (first dimesional of the data)\n",
    "  x_test=testing_point[0:dim]\n",
    "\n",
    "  # Loop through the dataset to extract the vec_x and y parameters\n",
    "  for each in range(len(dataset)):\n",
    "    # Extract the feature values (x_train) and class label (last element)\n",
    "    x_train=dataset[each][0:dim]\n",
    "    y_train=dataset[each][dim]\n",
    "    # To-Do\n",
    "    # Calculate the distance between the training point and testing point\n",
    "    # using the previously defined distance function\n",
    "    dist = distance(x_train, x_test)\n",
    "    # If the distance is smaller than the current minimum distance,\n",
    "    # update the minimum distance and minimum label accordingly\n",
    "    if dist < min_length:\n",
    "      # To-Do\n",
    "      # replace min_length with the new dist\n",
    "      # replace min_label with the new label\n",
    "      min_length = dist\n",
    "      min_label = y_train\n",
    "  # Return the label of the nearest neighbor\n",
    "  return (min_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "R9o25ocesDwG"
   },
   "outputs": [],
   "source": [
    "def generate_samples(target_num_samples,dim):\n",
    "    # Initilize the dataset\n",
    "    Sn = [] # List to store negative samples\n",
    "    Sp = [] # List to store positive samples\n",
    "    num_n = 0 # Counter for negative samples\n",
    "    num_p = 0 # Counter for positive samples\n",
    "\n",
    "    # Generate samples until the target number is reached for both positive and negative samples\n",
    "    while num_p < target_num_samples*2 or num_n < target_num_samples*2:\n",
    "      # Generate a random vector within the range [-5, 5] with dimension (dim+1)\n",
    "      random_sample = np.random.uniform(-5, 5, (dim+1))\n",
    "      # Set the last dimension to 0 temporally\n",
    "      random_sample[dim] = 0\n",
    "      # Compute the sum of the vector components\n",
    "      sum = np.sum(random_sample)\n",
    "      # If the sum is positive, append the sample to Sp\n",
    "      if sum > 0:\n",
    "        if num_p < target_num_samples*2:\n",
    "          random_sample[dim] = 1\n",
    "          Sp.append(random_sample)\n",
    "          num_p +=1\n",
    "      elif num_n < target_num_samples*2:\n",
    "        random_sample[dim] = -1\n",
    "        Sn.append(random_sample)\n",
    "        num_n +=1\n",
    "\n",
    "\n",
    "    # Split the dataset in to training (Sp, Sn) and testing (Tp, Tn)\n",
    "    # The last target_num_samples samples from Sn and Sp are used for testing.\n",
    "    Tp = Sp[target_num_samples:]\n",
    "    Tn = Sn[target_num_samples:]\n",
    "\n",
    "    # The first target_num_samples samples from Sn and Sp are used for training.\n",
    "    Sp = Sp[:target_num_samples]\n",
    "    Sn = Sn[:target_num_samples]\n",
    "\n",
    "    # Combine positive and negative samples to create the dataset\n",
    "    training_samples = Sn + Sp\n",
    "    # Combine positive and negative samples to create the dataset\n",
    "    testing_samples = Tp + Tn\n",
    "\n",
    "    return training_samples, testing_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6909,
     "status": "ok",
     "timestamp": 1714026023127,
     "user": {
      "displayName": "Yen-Kuang Chen",
      "userId": "09824706370308406166"
     },
     "user_tz": 420
    },
    "id": "iFsBMaYMoJqj",
    "outputId": "37bee580-ef54-499d-c0b3-d18af1c0a83c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension = 2\n",
      "Precision (average & SD): 0.9394073841311019 0.057954500980712656\n",
      "Recall (average & SD): 0.9316666666666665 0.07470311610338323\n",
      "F1 (average & SD): 0.9325838234498713 0.04808837237515327\n",
      "Dimension = 10\n",
      "Precision (average & SD): 0.7671916283856036 0.03047581407750054\n",
      "Recall (average & SD): 0.7613333333333334 0.04208985098043893\n",
      "F1 (average & SD): 0.7637156105516303 0.03101442259934923\n"
     ]
    }
   ],
   "source": [
    "# Define dimension of the data\n",
    "for dim in [2, 10]:\n",
    "  print (\"Dimension =\", dim)\n",
    "  # Define the number of samples to generate\n",
    "  target_num_samples=10*dim # This is the number of positive samples in the testing set\n",
    "  knn_precision_list = []\n",
    "  knn_recall_list = []\n",
    "  knn_f1_list = []\n",
    "  # Try 30 times\n",
    "  for r in range(30):\n",
    "    dataset, testing_dataset = generate_samples(target_num_samples,dim)\n",
    "    true_positive = 0  # Counter for true positive samples\n",
    "    true_negative = 0  # Counter for true negative samples\n",
    "    false_positive = 0 # Counter for false positive samples\n",
    "    false_negative = 0 # Counter for false negative samples\n",
    "    # Loop through the testing_dataset\n",
    "    for each in range(len(testing_dataset)):\n",
    "      # Make a prediction using the knn_inferencing function with the training dataset and the testing sample\n",
    "      prediction = knn_inferencing(dataset, testing_dataset[each], dim)\n",
    "      # Increment the appropriate counters based on whether the inferencing is true positive, true negative, false positive or false negative\n",
    "      if testing_dataset[each][dim] == 1:\n",
    "        if prediction == 1:\n",
    "            # To-Do\n",
    "            # increment the appropriate counter\n",
    "            true_positive += 1\n",
    "        else :\n",
    "            # To-Do\n",
    "            # increment the appropriate counter\n",
    "            false_negative += 1\n",
    "      else :\n",
    "        if prediction == -1:\n",
    "            # To-Do\n",
    "            # increment the appropriate counter\n",
    "            true_negative += 1\n",
    "        else :\n",
    "            # To-Do\n",
    "            # increment the appropriate counter\n",
    "            false_positive += 1\n",
    "    # Calculate precision\n",
    "    # To-Do\n",
    "    # calculate the precision using the the appropriate counters\n",
    "    precision = true_positive/(false_positive + true_positive)\n",
    "    knn_precision_list.append(precision)\n",
    "\n",
    "    # Calculate recall\n",
    "    # To-Do\n",
    "    # calculate the recall using the the appropriate counters\n",
    "    recall = true_positive/(false_negative + true_positive)\n",
    "    knn_recall_list.append(recall)\n",
    "\n",
    "    # Calculate F1 score\n",
    "    # To-Do\n",
    "    # calculate the score using precision and recall\n",
    "    precision_inv = 1/precision\n",
    "    recall_inv = 1/recall\n",
    "    f1 = 2/(precision_inv + recall_inv)\n",
    "    knn_f1_list.append(f1)\n",
    "\n",
    "  # print the result\n",
    "  print(\"Precision (average & SD):\", np.mean(knn_precision_list), np.std(knn_precision_list))\n",
    "  print(\"Recall (average & SD):\", np.mean(knn_recall_list), np.std(knn_recall_list))\n",
    "  print(\"F1 (average & SD):\", np.mean(knn_f1_list), np.std(knn_f1_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
